---
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

### 1. Suggest

Here you'll suggest matching candidates in a first R session.

#### Use R packages

Installing tilt.company.match should automatically install other useful packages. You can use them all with:

```{r}
library(dplyr, warn.conflicts = FALSE)
library(vroom, warn.conflicts = FALSE)
library(stringdist)
library(tilt.company.match)
```

#### Read the datasets

This example uses "demo" datasets. You should use your real `loanbook` and `tilt` datasets instead.

```{r}
# TODO: Replace with the path/to/your/real/loanbook.csv
loanbook_csv <- example_file("demo_loanbook.csv")
loanbook_csv

loanbook <- vroom(loanbook_csv, show_col_types = FALSE)
loanbook

# TODO: Replace with the path/to/your/real/tilt.csv
tilt_csv <- example_file("demo_tilt.csv")
tilt_csv

tilt <- vroom(tilt_csv, show_col_types = FALSE)
tilt
```

#### Check data quality

Let's first check you `loanbook` is as we expect.

##### Expected columns

Do you have the expected columns `id`, `company_name`, `postcode`, and `country`?

```{r}
expected <- c("id", "company_name", "postcode", "country")
loanbook %>% check_crucial_names(expected)

# Anything different throws an error
bad <- rename(loanbook, ids = id)
bad %>%
  check_crucial_names(expected) %>%
  try()
```

##### Duplicates

Do you have any duplicates in the column `id`?

```{r}
has_no_duplicates <- identical(anyDuplicated(loanbook$id), 0L)
# If you get an error, remove the duplicates and try again
stopifnot(has_no_duplicates)
```

Do you have duplicates in `company_name`, `postcode` or `country`?

It's best if there is none. But if you find duplicates and they belong to
different companies, then you don't have to fix them.

```{r}
best_without_duplicates <- c("company_name", "postcode", "country")
report_duplicates(loanbook, best_without_duplicates)
```

For example, here the column `misc_info` suggests the duplicates belong to
different companies, so it's OK:

```{r}
loanbook %>%
  filter(company_name == "Peasant Peter") %>%
  filter(postcode == "01234")
```

##### Missing values

Do you have missing values (`NA`s) in non-nullable columns?

Non-nullable columns must not have missing values. If they do you have to remove
them. Missing values in other columns are fine.

```{r}
non_nullable <- c("id", "company_name")
loanbook %>% abort_if_incomplete(non_nullable)
```

For example, here the non-nullable `id` column has one missing value:

```{r}
bad_loanbook <- tribble(
  ~id, ~company_name, ~postcode, ~country, ~misc_info,
  NA, "John Meier's Groceries", "55555", "germany", "Y",
  11, "John Meier's Groceries", "55555", "norway", "Y"
)
bad_loanbook %>%
  abort_if_incomplete(non_nullable) %>%
  try()

fixed_loanbook <- filter(bad_loanbook, !is.na(id))
# NA's are OK in columns other than non-nullable ones
fixed_loanbook

fixed_loanbook %>% abort_if_incomplete(non_nullable)
```

#### Create a standard alias of `company_name` in both datasets

Use `to_alias()` to reduce the chance you'll miss a match because of spurious
differences in the company name between the loanbook and tilt dataset. This
helps you get a less noisy, more consistent version of `company_name` in each of
the two datasets.

```{r}
loanbook_alias <- loanbook %>% mutate(company_alias = to_alias(company_name))
loanbook_alias

tilt_alias <- tilt %>% mutate(company_alias = to_alias(company_name))
tilt_alias
```

#### Match candidates

To inform the decision about which companies in your `loanbook` match companies in the `tilt`
dataset, we compare the values in the columns `postcode` and `country`:

* If your `loanbook` has both `postcode` and `country` we match companies in that specific `postcode` and that specific `country`. You will likely match companies that are really the same (true positives) because it's unlikely that two companies with similar name will be located close to each other. This will cost you the minimum amount of manual-validation work ahead.

```{r}
lacks_none <- loanbook_alias %>%
  filter(!is.na(postcode) & !is.na(country)) %>%
  left_join(
    tilt_alias,
    by = c("country", "postcode"),
    suffix = c("", "_tilt"),
    multiple = "all"
  )
```

* If your `loanbook` lacks `postcode` but has `country` we match companies in that specific `country` but across every `postcode`. You will possibly match companies that are not really
the same (false positives) but happen to have a similar name and are located in
the same `country`. This will cost you additional manual-validation work ahead.

```{r}
lacks_postcode <- loanbook_alias %>%
  filter(is.na(postcode) & !is.na(country)) %>%
  left_join(
    tilt_alias,
    by = c("country"),
    suffix = c("", "_tilt"),
    multiple = "all"
  )
```

* If your `loanbook` has `postcode` but lacks `country` we match companies with the same `postcode` but  across every `country`. You will possibly match companies that are not really
the same (false positives) but happen to have a similar name and the same
postcode. This will cost you additional manual-validation work ahead.

```{r}
lacks_country <- loanbook_alias %>%
  filter(!is.na(postcode) & is.na(country)) %>%
  left_join(tilt_alias, by = c("postcode"), suffix = c("", "_tilt"))
```

* If your `loanbook` lacks both `postcode` and `country` we match companies across the entire dataset.  You will most likely match companies that are not really
the same (false positives). This will cost you the greatest amount of additional
manual-validation work ahead.

```{r}
lacks_both <- loanbook_alias %>%
  filter(is.na(postcode) & is.na(country)) %>%
  mutate(postcode = "join_helper") %>%
  inner_join(
    dplyr::mutate(tilt_alias, postcode = "join_helper"),
    by = c("postcode"),
    suffix = c("", "_tilt"),
    multiple = "all"
  ) %>%
  mutate(postcode = NA_character_)
```

Having considered all cases, you can now combine them all in a single dataset:

```{r}
candidates <- bind_rows(lacks_none, lacks_postcode, lacks_country, lacks_both)

candidates
```

Above each join allowed any one company in your `loanbook` to match `"all"` of
the potentially `multiple` companies the `tilt` dataset. Here, for example, one
company in our demo `loanbook` matches three candidates in our demo `tilt`
dataset:

```{r}
candidates %>%
  filter(id == 1) %>%
  select(company_alias, id_tilt, company_alias_tilt)
```

Next, calculate the string similarity between the aliased `company_name` from
the loanbook and tilt datasets. Complete similarity corresponds to `1`, and
complete dissimilarity corresponds to `0`. For each company in the loanbook,
arrange matching candidates by descending similarity.

```{r}
okay_candidates <- candidates %>%
  # Other parameters may perform best. See `?stringdist::stringsim`
  mutate(similarity = stringsim(
    company_alias, company_alias_tilt,
    # Good to compare human typed text that might have typos.
    method = "jw",
    p = 0.1
  )) %>%
  # Arrange matching candidates from more to less similar
  arrange(id, -similarity)

okay_candidates %>% relocate(similarity)
```

#### Pick best candidates

```{r}
eligibility_threshold <- 0.75
```

Empirically we found that candidates under a `similarity` threshold of 
`r eligibility_threshold` are most likely false positives. Pick `similarity`
values above that threshold to drastically reduce the number of candidates
you'll need to validate manually. We believe this benefit outweighs the
potential loss of a few true positives.

```{r}
best_candidates <- okay_candidates %>%
  filter(similarity > eligibility_threshold | is.na(similarity))
```

After picking the best candidates, some companies in your `loanbook` might no
longer have any candidate in the `tilt` dataset.

```{r}
unmatched <- anti_join(
  okay_candidates %>% distinct(id, company_name),
  best_candidates %>% distinct(id, company_name)
)

unmatched
```

#### Suggest matches

```{r}
# Decided upon extensive experience
suggestion_threshold <- 0.9
```

Later you'll need to manually decide which of all candidates if any is a true
match. To make that job easier, we can automatically make some suggestions in a
new column `suggest_match`.

The values of `suggest_match` are set to `TRUE` where the value of `similarity`
meets all of these conditions:

* It's the highest among all other candidates.
* It's above a threshold of `r suggestion_threshold`.
* It's the only such highest value in the group defined by a combination of `company_name` x `postcode` -- to avoid duplicates.

```{r}
candidates_suggest_match <- best_candidates %>%
  # - It's the highest among all other candidates.
  group_by(id) %>%
  filter(similarity == max(similarity)) %>%
  # - It's above the threshold.
  filter(similarity > suggestion_threshold) %>%
  # - It's the only such highest value in the group defined by a combination of
  # `company_name` x `postcode` -- to avoid duplicates.
  mutate(duplicates = any(duplicated_paste(company_name, postcode))) %>%
  filter(!duplicates) %>%
  select(id, id_tilt) %>%
  mutate(suggest_match = TRUE) %>%
  ungroup()
```

In all other rows the value of `suggest_match` is automatically set to `NA`.
Also now create a new column `accept_match` and fill it with `NA`. Later you'll
edit this column.

```{r}
to_edit <- best_candidates %>%
  left_join(candidates_suggest_match, by = c("id", "id_tilt")) %>%
  mutate(accept_match = NA)

to_edit %>% relocate(similarity, suggest_match)
```

Note that even a `similarity` of `1` in the same `postcode` can be a false
positive. For example, this is false positive:

```{r}
to_edit %>%
  filter(id == 4, id_tilt == 4) %>%
  select(suggest_match, similarity, postcode, matches("misc_info"))
```

Now write the dataset `to_edit` so that you can explore it in a spreadsheet
editor. For example, you may write it as a .csv or .xlsx file then open it in
Excel or GoogleSheets.

```r
vroom::vroom_write(to_edit, "to_edit.csv", delim = ",")

# Or, you can install the writexl package with: `install.packages("writexl")`
writexl::write_xlsx(to_edit, "to_edit.xlsx")
```
